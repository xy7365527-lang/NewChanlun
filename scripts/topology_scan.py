#!/usr/bin/env python3
"""æ‹“æ‰‘æ‰«æï¼šä»åˆ†å¸ƒå¼æ–‡ä»¶å¼•ç”¨ä¸­æå–çŸ¥è¯†å›¾è°±å¹¶åˆ†æè¿é€šæ€§ã€‚

å›¾å·²ç»åˆ†å¸ƒå¼åœ°å­˜åœ¨äºæ‰€æœ‰æ–‡ä»¶çš„äº¤å‰å¼•ç”¨ä¸­ï¼š
- å®šä¹‰æ–‡ä»¶ (.chanlun/definitions/*.md) å¼•ç”¨ specã€src
- è°±ç³»æ¡ç›® (.chanlun/genealogy/**/*.md) å¼•ç”¨å®šä¹‰ã€å…¶ä»–è°±ç³»
- Skill æ–‡ä»¶ (.claude/skills/**/SKILL.md) æœ‰ genealogy_source frontmatter
- Spec æ–‡ä»¶ (docs/spec/*.md) å¼•ç”¨å…¶ä»– specã€å®šä¹‰

æœ¬å·¥å…·ä¸åˆ›å»ºå›¾ï¼Œåªè¯»å–å·²å­˜åœ¨çš„å›¾å¹¶åˆ†æè¿é€šæ€§ã€‚

ç”¨æ³•ï¼š
    python scripts/topology_scan.py
"""

from __future__ import annotations

import re
from collections import defaultdict
from pathlib import Path


ROOT = Path(__file__).resolve().parent.parent

# â”€â”€ èŠ‚ç‚¹ç±»å‹ â”€â”€

NODE_TYPES = {
    "definition": ".chanlun/definitions",
    "genealogy_settled": ".chanlun/genealogy/settled",
    "genealogy_pending": ".chanlun/genealogy/pending",
    "skill": ".claude/skills",
    "spec": "docs/spec",
    "source": "src/newchan",
}


def _scan_md_files(rel_dir: str, recursive: bool = False) -> list[Path]:
    """æ‰«æç›®å½•ä¸‹çš„ .md æ–‡ä»¶ã€‚"""
    d = ROOT / rel_dir
    if not d.exists():
        return []
    pattern = "**/*.md" if recursive else "*.md"
    return sorted(d.glob(pattern))


def _node_id(path: Path) -> str:
    """æ–‡ä»¶è·¯å¾„ â†’ èŠ‚ç‚¹ IDã€‚"""
    return str(path.relative_to(ROOT))


def _extract_references(content: str, source_id: str) -> list[tuple[str, str, str]]:
    """ä»æ–‡ä»¶å†…å®¹ä¸­æå–å¯¹å…¶ä»–èŠ‚ç‚¹çš„å¼•ç”¨ã€‚

    è¿”å› (source, target, edge_type) ä¸‰å…ƒç»„åˆ—è¡¨ã€‚
    """
    edges = []

    # 1. YAML frontmatter: genealogy_source
    m = re.search(r"genealogy_source:\s*[\"']?(\d+\w*)[\"']?", content)
    if m:
        gen_id = m.group(1)
        # å°è¯•åŒ¹é…è°±ç³»æ–‡ä»¶
        target = _find_genealogy_file(gen_id)
        if target:
            edges.append((source_id, target, "genealogy_source"))
        else:
            edges.append((source_id, f"MISSING:genealogy/{gen_id}", "genealogy_source_broken"))

    # 2. è°±ç³»æ¡ç›®ä¸­çš„å¼•ç”¨: "å‰ç½®: 022-xxx" æˆ– "å…³è”: xxx"
    for pattern, edge_type in [
        (r"å‰ç½®:\s*(.+)", "depends_on"),
        (r"å…³è”:\s*(.+)", "related_to"),
    ]:
        m = re.search(pattern, content)
        if m:
            refs = m.group(1)
            for ref in re.split(r"[,ï¼Œ]\s*", refs):
                ref = ref.strip()
                if not ref or ref == "æ— ":
                    continue
                target = _resolve_reference(ref)
                edges.append((source_id, target, edge_type))

    # 3. æ˜¾å¼æ–‡ä»¶è·¯å¾„å¼•ç”¨: `docs/spec/xxx.md`, `src/newchan/xxx.py`
    for fpath in re.findall(r"`((?:docs/spec|src/newchan|\.chanlun/\w+)/[\w./\-]+\.\w+)`", content):
        # æˆªæ–­ :: åçš„å‡½æ•°åï¼Œåªå–æ–‡ä»¶è·¯å¾„
        target = fpath.split("::")[0].strip()
        if (ROOT / target).exists():
            edges.append((source_id, target, "references"))
        else:
            edges.append((source_id, f"MISSING:{target}", "reference_broken"))

    # 4. è°±ç³»å·å¼•ç”¨: NNNå·è°±ç³»
    for gen_num in re.findall(r"(\d{3})å·è°±ç³»", content):
        target = _find_genealogy_file(gen_num)
        if target:
            edges.append((source_id, target, "cites_genealogy"))

    # 5. å®šä¹‰æ–‡ä»¶å¼•ç”¨: xxx.md (åœ¨ .chanlun/definitions/ ä¸­)
    for def_ref in re.findall(r"(?:å®šä¹‰æ–‡ä»¶|definitions/)([\w]+)\.md", content):
        target = f".chanlun/definitions/{def_ref}.md"
        if (ROOT / target).exists():
            edges.append((source_id, target, "references_definition"))

    return edges


def _find_genealogy_file(gen_id: str) -> str | None:
    """æ ¹æ®è°±ç³»å·æ‰¾åˆ°å¯¹åº”æ–‡ä»¶ã€‚"""
    gen_id = gen_id.strip()
    for subdir in ["settled", "pending"]:
        d = ROOT / ".chanlun" / "genealogy" / subdir
        if not d.exists():
            continue
        for f in d.glob("*.md"):
            if f.name.startswith(gen_id):
                return str(f.relative_to(ROOT))
    return None


def _resolve_reference(ref: str) -> str:
    """è§£æå¼•ç”¨æ–‡æœ¬ä¸ºèŠ‚ç‚¹ IDã€‚"""
    ref = ref.strip()

    # è°±ç³»ç¼–å·: 022-xxx
    m = re.match(r"(\d{3})-[\w-]+", ref)
    if m:
        target = _find_genealogy_file(m.group(1))
        return target or f"MISSING:genealogy/{ref}"

    # å®šä¹‰å: bi.md, dengjia.md
    if ref.endswith(".md"):
        for d in [".chanlun/definitions", "docs/spec"]:
            target = f"{d}/{ref}"
            if (ROOT / target).exists():
                return target
        return f"MISSING:{ref}"

    # æ–‡ä»¶è·¯å¾„
    if (ROOT / ref).exists():
        return ref

    return f"UNRESOLVED:{ref}"


def build_graph() -> tuple[set[str], list[tuple[str, str, str]]]:
    """æ„å»ºçŸ¥è¯†å›¾è°±ã€‚è¿”å› (èŠ‚ç‚¹é›†, è¾¹åˆ—è¡¨)ã€‚"""
    nodes: set[str] = set()
    edges: list[tuple[str, str, str]] = []

    # æ‰«ææ‰€æœ‰èŠ‚ç‚¹æ¥æº
    sources = [
        (".chanlun/definitions", False),
        (".chanlun/genealogy/settled", False),
        (".chanlun/genealogy/pending", False),
        ("docs/spec", False),
        (".claude/skills", True),
    ]

    for rel_dir, recursive in sources:
        for path in _scan_md_files(rel_dir, recursive):
            node_id = _node_id(path)
            nodes.add(node_id)
            content = path.read_text(encoding="utf-8")
            file_edges = _extract_references(content, node_id)
            edges.extend(file_edges)
            # è¢«å¼•ç”¨çš„ç›®æ ‡ä¹Ÿæ˜¯èŠ‚ç‚¹
            for _, target, _ in file_edges:
                nodes.add(target)

    return nodes, edges


def analyze_connectivity(
    nodes: set[str], edges: list[tuple[str, str, str]]
) -> dict:
    """åˆ†æå›¾çš„è¿é€šæ€§ã€‚"""
    out_edges: dict[str, list[tuple[str, str]]] = defaultdict(list)
    in_edges: dict[str, list[tuple[str, str]]] = defaultdict(list)

    for src, tgt, etype in edges:
        out_edges[src].append((tgt, etype))
        in_edges[tgt].append((src, etype))

    # æ‚¬ç©ºèŠ‚ç‚¹: æœ‰å…¥è¾¹æ— å‡ºè¾¹ï¼ˆè¢«å¼•ç”¨ä½†ä¸å¼•ç”¨åˆ«äººâ€”â€”å¯èƒ½æ˜¯å¶å­èŠ‚ç‚¹ï¼‰
    # å­¤ç«‹èŠ‚ç‚¹: æ— å…¥è¾¹æ— å‡ºè¾¹ï¼ˆå®Œå…¨æ–­è¿ï¼‰
    # ç¼ºå¤±èŠ‚ç‚¹: ä»¥ MISSING: å¼€å¤´çš„è™šæ‹ŸèŠ‚ç‚¹
    real_nodes = {n for n in nodes if not n.startswith(("MISSING:", "UNRESOLVED:"))}
    missing_nodes = {n for n in nodes if n.startswith("MISSING:")}
    unresolved_nodes = {n for n in nodes if n.startswith("UNRESOLVED:")}

    isolated = {n for n in real_nodes if n not in out_edges and n not in in_edges}
    leaf_only = {n for n in real_nodes if n not in out_edges and n in in_edges}
    root_only = {n for n in real_nodes if n in out_edges and n not in in_edges}

    return {
        "total_nodes": len(real_nodes),
        "total_edges": len(edges),
        "missing_references": sorted(missing_nodes),
        "unresolved_references": sorted(unresolved_nodes),
        "isolated_nodes": sorted(isolated),
        "root_only": sorted(root_only),  # åªæœ‰å‡ºè¾¹ï¼ˆå¼•ç”¨åˆ«äººä½†æ²¡äººå¼•ç”¨ï¼‰
        "leaf_only": sorted(leaf_only),   # åªæœ‰å…¥è¾¹ï¼ˆè¢«å¼•ç”¨ä½†ä¸å¼•ç”¨åˆ«äººï¼‰
    }


def print_report(nodes: set[str], edges: list[tuple[str, str, str]], analysis: dict):
    """è¾“å‡ºè¿é€šæ€§æŠ¥å‘Šã€‚"""
    print("=" * 60)
    print("  çŸ¥è¯†æ‹“æ‰‘è¿é€šæ€§åˆ†æ")
    print("=" * 60)

    print(f"\nèŠ‚ç‚¹: {analysis['total_nodes']}  è¾¹: {analysis['total_edges']}")

    # æŒ‰ç±»å‹ç»Ÿè®¡èŠ‚ç‚¹
    type_counts: dict[str, int] = defaultdict(int)
    for n in nodes:
        if n.startswith("MISSING:") or n.startswith("UNRESOLVED:"):
            continue
        if n.startswith(".chanlun/definitions/"):
            type_counts["å®šä¹‰"] += 1
        elif n.startswith(".chanlun/genealogy/settled/"):
            type_counts["è°±ç³»(å·²ç»“ç®—)"] += 1
        elif n.startswith(".chanlun/genealogy/pending/"):
            type_counts["è°±ç³»(ç”Ÿæˆæ€)"] += 1
        elif n.startswith("docs/spec/"):
            type_counts["è§„èŒƒ"] += 1
        elif n.startswith(".claude/skills/"):
            type_counts["Skill"] += 1
        elif n.startswith("src/"):
            type_counts["ä»£ç "] += 1
        else:
            type_counts["å…¶ä»–"] += 1

    print("\nèŠ‚ç‚¹åˆ†å¸ƒ:")
    for t, c in sorted(type_counts.items()):
        print(f"  {t}: {c}")

    # è¾¹ç±»å‹ç»Ÿè®¡
    edge_counts: dict[str, int] = defaultdict(int)
    for _, _, etype in edges:
        edge_counts[etype] += 1
    print("\nè¾¹ç±»å‹:")
    for t, c in sorted(edge_counts.items()):
        print(f"  {t}: {c}")

    # é—®é¢˜æŠ¥å‘Š
    if analysis["missing_references"]:
        print(f"\nâš  æ–­è£‚å¼•ç”¨ ({len(analysis['missing_references'])}):")
        for n in analysis["missing_references"]:
            print(f"  {n}")

    if analysis["unresolved_references"]:
        print(f"\nâš  æœªè§£æå¼•ç”¨ ({len(analysis['unresolved_references'])}):")
        for n in analysis["unresolved_references"]:
            print(f"  {n}")

    if analysis["isolated_nodes"]:
        print(f"\nğŸ”´ å­¤ç«‹èŠ‚ç‚¹ ({len(analysis['isolated_nodes'])}):")
        print("  ï¼ˆæ— å…¥è¾¹æ— å‡ºè¾¹â€”â€”å®Œå…¨æ–­è¿ï¼Œå¯èƒ½æ˜¯æœªç»“æ™¶çš„çŸ¥è¯†ï¼‰")
        for n in analysis["isolated_nodes"]:
            print(f"  {n}")

    if analysis["root_only"]:
        print(f"\nğŸŸ¡ æ ¹èŠ‚ç‚¹ ({len(analysis['root_only'])}):")
        print("  ï¼ˆå¼•ç”¨åˆ«äººä½†æ²¡äººå¼•ç”¨â€”â€”å¯èƒ½æ˜¯å…¥å£ç‚¹æˆ–æ‚¬ç©ºå¼•ç”¨æºï¼‰")
        for n in analysis["root_only"]:
            print(f"  {n}")

    print(f"\n{'=' * 60}")
    if not analysis["missing_references"] and not analysis["isolated_nodes"]:
        print("âœ… æ— æ–­è£‚å¼•ç”¨ï¼Œæ— å­¤ç«‹èŠ‚ç‚¹")
    else:
        total_issues = len(analysis["missing_references"]) + len(analysis["isolated_nodes"])
        print(f"ğŸ“Œ {total_issues} ä¸ªé—®é¢˜éœ€è¦å…³æ³¨")


def main():
    nodes, edges = build_graph()
    analysis = analyze_connectivity(nodes, edges)
    print_report(nodes, edges, analysis)


if __name__ == "__main__":
    main()
