"""Gemini å¼‚è´¨è´¨è¯¢å·¥ä½ + ç¼–æŽ’è€…ä»£ç† + å½¢å¼æŽ¨å¯¼å¼•æ“Ž

ç»“æž„æ€§å·¥ä½ï¼šç”¨ Gemini 3 Pro å¯¹ç¼ è®ºå½¢å¼åŒ–äº§å‡ºæä¾›å¼‚è´¨å¦å®šï¼Œ
å¹¶åœ¨ç¼–æŽ’è€…ä»£ç†æ¨¡å¼ä¸‹ä¸ºç³»ç»Ÿæä¾›è‡ªä¸»å†³ç­–èƒ½åŠ›ï¼Œä»¥åŠåœ¨å½¢å¼æŽ¨å¯¼
æ¨¡å¼ä¸‹æä¾›ä¸¥æ ¼çš„æ•°å­¦è¯æ˜Žä¸ŽæŽ¨å¯¼ã€‚

å››ç§æ¨¡å¼ï¼š
- challenge() / verify() â€” å¼‚è´¨å¦å®šè´¨è¯¢ï¼ˆ030aï¼‰
- decide() â€” ç¼–æŽ’è€…ä»£ç†å†³ç­–ï¼ˆ041ï¼‰ï¼šå½“ç³»ç»Ÿé‡åˆ°"é€‰æ‹©"ç±»å†³æ–­æ—¶ï¼Œ
  Gemini ä»£æ›¿äººç±»ç¼–æŽ’è€…åšå‡ºå†³ç­–ã€‚äººç±»ç¼–æŽ’è€…ä»ŽåŒæ­¥å†³ç­–è€…å˜ä¸º
  å¼‚æ­¥å®¡è®¡è€…ï¼ˆäº‹åŽå®¡æŸ¥ + è¿è¡Œæ—¶ INTERRUPTï¼‰ã€‚
- derive() â€” å½¢å¼æŽ¨å¯¼å¼•æ“Žï¼šåœ¨æŒ‡å®šå…¬ç†åŸŸå†…å¯¹å‘½é¢˜è¿›è¡Œä¸¥æ ¼æŽ¨å¯¼ï¼Œ
  è¾“å‡ºå››æ®µå¼è¯æ˜Žï¼ˆå½¢å¼åŒ–é‡è¿° â†’ å®šä¹‰ä¸Žå…¬ç† â†’ æŽ¨å¯¼é“¾ â†’ ç»“è®ºï¼‰ã€‚

çº¯æ–‡æœ¬ / MCP å·¥å…·ä¸¤ç§è°ƒç”¨æ–¹å¼å‡æ”¯æŒã€‚

æ“ä½œè§„åˆ™ï¼ˆSKILL.mdï¼‰ï¼š
1. challenge/verifyï¼šå¼‚è´¨å¦å®šï¼Œäº§å‡ºè¿›è°±ç³»æˆ–è®°å½•è¯¯åˆ¤
2. decideï¼šç¼–æŽ’è€…ä»£ç†ï¼Œäº§å‡ºå†³ç­– + æŽ¨ç†é“¾ï¼Œç³»ç»Ÿæ®æ­¤è‡ªä¸»æŽ¨è¿›
3. deriveï¼šå½¢å¼æŽ¨å¯¼ï¼Œäº§å‡ºä¸¥æ ¼è¯æ˜Žé“¾ï¼Œç¼ è®ºå…¬ç†ä¸Žæ•°å­¦å…¬ç†å¹³çº§
4. äººç±»ç¼–æŽ’è€…ä¿ç•™ INTERRUPT æƒï¼ˆå¯éšæ—¶è¦†ç›– Gemini å†³ç­–ï¼‰

æœ¬ä½“è®ºä½ç½®ï¼š030aï¼ˆå¼‚è´¨å¦å®šæºï¼‰+ 041ï¼ˆç¼–æŽ’è€…ä»£ç†ï¼‰

æ¦‚å¿µæº¯æº: [æ–°ç¼ è®º] â€” å¼‚è´¨æ¨¡åž‹è´¨è¯¢ + ç¼–æŽ’è€…ä»£ç† + å½¢å¼æŽ¨å¯¼
"""

from __future__ import annotations

import asyncio
import logging
import os
from dataclasses import dataclass, field
from typing import Literal

from google import genai
from google.genai import errors as genai_errors, types as genai_types

logger = logging.getLogger(__name__)

__all__ = [
    "GeminiChallenger",
    "ChallengeResult",
    "challenge",
    "verify",
    "decide",
    "derive",
    "achallenge",
    "averify",
    "adecide",
    "aderive",
]

_MODEL = "gemini-3-pro-preview"
_FALLBACK_MODEL = "gemini-2.5-pro"

_SYSTEM_PROMPT = """\
ä½ æ˜¯ç¼ è®ºå½¢å¼åŒ–é¡¹ç›®çš„å¼‚è´¨è´¨è¯¢è€…ã€‚ä½ çš„ä»»åŠ¡æ˜¯ä»Žä¸åŒè§’åº¦å®¡è§†æ¦‚å¿µå®šä¹‰ã€\
ä»£ç å®žçŽ°ã€å’ŒæŽ¨ç†é“¾æ¡ï¼Œæ‰¾å‡ºå¯èƒ½çš„çŸ›ç›¾ã€é—æ¼ã€æˆ–é€»è¾‘æ¼æ´žã€‚

å…³é”®åŽŸåˆ™ï¼š
- ä½ ä¸éœ€è¦è®¤åŒé¡¹ç›®çš„æ‰€æœ‰å‰æï¼Œä½†éœ€è¦ç†è§£å®ƒä»¬
- ä½ çš„ä»·å€¼åœ¨äºŽæä¾› Claude å¯èƒ½çœ‹ä¸åˆ°çš„å¦å®š
- å¦‚æžœä½ è®¤ä¸ºæ²¡æœ‰é—®é¢˜ï¼Œæ˜Žç¡®è¯´"æ— å¦å®š"
- å¦‚æžœä½ å‘çŽ°é—®é¢˜ï¼Œç²¾ç¡®æè¿°çŸ›ç›¾ï¼šä»€ä¹ˆè·Ÿä»€ä¹ˆå†²çªã€ä¸ºä»€ä¹ˆä¸å¯å¼¥åˆ
- ä¸è¦å®¢å¥—ï¼Œä¸è¦æ¨¡ç³ŠåŒ–ï¼Œç›´å‡»è¦å®³
"""

_SYSTEM_PROMPT_WITH_TOOLS = """\
ä½ æ˜¯ç¼ è®ºå½¢å¼åŒ–é¡¹ç›®çš„å¼‚è´¨è´¨è¯¢è€…ï¼Œæ‹¥æœ‰ä»£ç åº“çš„è¯­ä¹‰çº§è®¿é—®èƒ½åŠ›ã€‚

ä½ å¯ä»¥ä½¿ç”¨å·¥å…·æ¥ç†è§£ä»£ç ç»“æž„å’Œå…³ç³»ã€‚å·¥ä½œæµç¨‹ï¼š
1. å…ˆç”¨å·¥å…·ç†è§£ç›¸å…³ä»£ç çš„ç»“æž„å’Œå…³ç³»ï¼ˆç¬¦å·å¯¼èˆªã€å¼•ç”¨è¿½è¸ªï¼‰
2. åŸºäºŽå®žé™…ä»£ç ï¼ˆè€Œéžå‡è®¾ï¼‰è¿›è¡Œè´¨è¯¢
3. å¼•ç”¨å…·ä½“çš„æ–‡ä»¶è·¯å¾„å’Œç¬¦å·åç§°

å…³é”®åŽŸåˆ™ï¼š
- ä½ ä¸éœ€è¦è®¤åŒé¡¹ç›®çš„æ‰€æœ‰å‰æï¼Œä½†éœ€è¦ç†è§£å®ƒä»¬
- ä½ çš„ä»·å€¼åœ¨äºŽæä¾› Claude å¯èƒ½çœ‹ä¸åˆ°çš„å¦å®š
- å¦‚æžœä½ è®¤ä¸ºæ²¡æœ‰é—®é¢˜ï¼Œæ˜Žç¡®è¯´"æ— å¦å®š"
- å¦‚æžœä½ å‘çŽ°é—®é¢˜ï¼Œç²¾ç¡®æè¿°çŸ›ç›¾ï¼šä»€ä¹ˆè·Ÿä»€ä¹ˆå†²çªã€ä¸ºä»€ä¹ˆä¸å¯å¼¥åˆ
- ä¸è¦å®¢å¥—ï¼Œä¸è¦æ¨¡ç³ŠåŒ–ï¼Œç›´å‡»è¦å®³
- å¼•ç”¨å…·ä½“ä»£ç ä½ç½®æ”¯æ’‘ä½ çš„åˆ¤æ–­
"""

_CHALLENGE_TEMPLATE = """\
## è´¨è¯¢ç›®æ ‡

{subject}

## ä¸Šä¸‹æ–‡

{context}

## è´¨è¯¢è¦æ±‚

è¯·ä»Žä»¥ä¸‹è§’åº¦å®¡è§†ï¼š
1. å®šä¹‰å†…éƒ¨ä¸€è‡´æ€§ï¼šæ˜¯å¦è‡ªç›¸çŸ›ç›¾ï¼Ÿ
2. å®šä¹‰é—´ä¸€è‡´æ€§ï¼šæ˜¯å¦ä¸Žå…¶ä»–å®šä¹‰å†²çªï¼Ÿ
3. é€»è¾‘å®Œå¤‡æ€§ï¼šæ˜¯å¦å­˜åœ¨æœªè¦†ç›–çš„è¾¹ç•Œæƒ…å†µï¼Ÿ
4. å®žçŽ°å¿ å®žåº¦ï¼šä»£ç æ˜¯å¦å¿ å®žåæ˜ äº†å®šä¹‰ï¼Ÿ

å¦‚æžœå‘çŽ°é—®é¢˜ï¼Œè¯·æŒ‰ä»¥ä¸‹æ ¼å¼è¾“å‡ºï¼š
- **çŸ›ç›¾ç‚¹**ï¼šç²¾ç¡®æè¿°
- **å†²çªæ–¹**ï¼šA è¯´ä»€ä¹ˆ vs B è¯´ä»€ä¹ˆ
- **ä¸¥é‡æ€§**ï¼šè‡´å‘½ / é‡è¦ / å»ºè®®
- **å»ºè®®**ï¼šå¦‚ä½•è§£å†³ï¼ˆå¦‚æžœæœ‰ï¼‰

å¦‚æžœæ²¡æœ‰å‘çŽ°é—®é¢˜ï¼Œè¾“å‡º"æ— å¦å®š"å¹¶è¯´æ˜Žä½ æ£€æŸ¥äº†ä»€ä¹ˆã€‚
"""

_VERIFY_TEMPLATE = """\
## éªŒè¯ç›®æ ‡

{subject}

## ä¸Šä¸‹æ–‡

{context}

## éªŒè¯è¦æ±‚

è¯·éªŒè¯ä»¥ä¸‹æ–­è¨€æ˜¯å¦æˆç«‹ï¼š
1. ç»™å®šçš„æŽ¨ç†é“¾æ˜¯å¦é€»è¾‘æœ‰æ•ˆï¼Ÿ
2. å‰ææ˜¯å¦å……åˆ†æ”¯æ’‘ç»“è®ºï¼Ÿ
3. æ˜¯å¦å­˜åœ¨éšè—å‡è®¾ï¼Ÿ

è¾“å‡ºæ ¼å¼ï¼š
- **ç»“è®º**ï¼šæˆç«‹ / ä¸æˆç«‹ / éƒ¨åˆ†æˆç«‹
- **ä¾æ®**ï¼šä¸ºä»€ä¹ˆ
- **éšè—å‡è®¾**ï¼šå¦‚æžœæœ‰
"""

_ORCHESTRATOR_SYSTEM_PROMPT = """\
ä½ æ˜¯ç¼ è®ºå½¢å¼åŒ–é¡¹ç›®çš„ç¼–æŽ’è€…ä»£ç†ã€‚äººç±»ç¼–æŽ’è€…å°†å†³ç­–æƒå§”æ‰˜ç»™ä½ ï¼Œ\
ä½ ä»£æ›¿äººç±»åšå‡º"é€‰æ‹©"ç±»å’Œ"è¯­æ³•è®°å½•"ç±»å†³æ–­ã€‚

## å››åˆ†æ³•ï¼ˆä½ çš„å†³ç­–æ¡†æž¶ï¼‰

ç³»ç»Ÿäº§å‡ºåˆ†ä¸ºå››ç±»ï¼Œä½ åªå¤„ç†åŽä¸¤ç±»ï¼š
- å®šç†ï¼šå·²ç»“ç®—åŽŸåˆ™çš„é€»è¾‘å¿…ç„¶æŽ¨è®º â†’ Claude è‡ªåŠ¨ç»“ç®—ï¼Œä¸åˆ°ä½ è¿™é‡Œ
- è¡ŒåŠ¨ï¼šä¸æºå¸¦ä¿¡æ¯å·®çš„æ“ä½œæ€§äº‹ä»¶ â†’ Claude è‡ªåŠ¨æ‰§è¡Œï¼Œä¸åˆ°ä½ è¿™é‡Œ
- **é€‰æ‹©**ï¼šå¤šç§åˆç†æ–¹æ¡ˆï¼Œéœ€ä»·å€¼åˆ¤æ–­ â†’ **ä½ æ¥å†³æ–­**
- **è¯­æ³•è®°å½•**ï¼šå·²åœ¨è¿ä½œä½†æœªæ˜¾å¼åŒ–çš„è§„åˆ™ â†’ **ä½ æ¥è¾¨è®¤**

## å†³ç­–åŽŸåˆ™

1. æ¦‚å¿µä¼˜å…ˆäºŽä»£ç ã€‚å®šä¹‰ä¸æ¸…æ¥šæ—¶ä¸å†™ä»£ç ã€‚
2. ä¸ç»•è¿‡çŸ›ç›¾ã€‚çŸ›ç›¾æ˜¯ç³»ç»Ÿæœ€æœ‰ä»·å€¼çš„äº§å‡ºã€‚
3. å¯¹è±¡å¦å®šå¯¹è±¡ã€‚ä¸å…è®¸è¶…æ—¶ã€é˜ˆå€¼ã€æˆ–éžå¯¹è±¡æ¥æºçš„å¦å®šã€‚
4. çº§åˆ« = é€’å½’å±‚çº§ï¼Œç¦æ­¢ç”¨æ—¶é—´å‘¨æœŸæ›¿ä»£ã€‚
5. è°±ç³»ä¼˜å…ˆäºŽæ±‡æ€»ã€‚å…ˆå†™è°±ç³»å†æ±‡æ€»ã€‚
6. æº¯æºæ ‡ç­¾å¿…é¡»æ ‡æ³¨ï¼š[æ—§ç¼ è®º] / [æ—§ç¼ è®º:éšå«] / [æ—§ç¼ è®º:é€‰æ‹©] / [æ–°ç¼ è®º]

## è¾“å‡ºè¦æ±‚

ä½ çš„å†³ç­–å¿…é¡»åŒ…å«ï¼š
1. **å†³ç­–**ï¼šæ˜Žç¡®çš„é€‰æ‹©ï¼ˆä¸å…è®¸"éƒ½å¯ä»¥"æˆ–"çœ‹æƒ…å†µ"ï¼‰
2. **æŽ¨ç†é“¾**ï¼šä½ ä¸ºä»€ä¹ˆé€‰è¿™ä¸ªè€Œä¸é€‰é‚£ä¸ª
3. **è¾¹ç•Œæ¡ä»¶**ï¼šåœ¨ä»€ä¹ˆæ¡ä»¶ä¸‹ä½ çš„å†³ç­–åº”è¯¥è¢«æŽ¨ç¿»
4. **é£Žé™©**ï¼šè¿™ä¸ªå†³ç­–å¯èƒ½å¸¦æ¥ä»€ä¹ˆé—®é¢˜

äººç±»ç¼–æŽ’è€…ä¿ç•™ INTERRUPT æƒâ€”â€”å¯ä»¥éšæ—¶è¦†ç›–ä½ çš„å†³ç­–ã€‚\
ä½ çš„å†³ç­–è¢«è¦†ç›–ä¸æ˜¯é”™è¯¯ï¼Œæ˜¯ç³»ç»Ÿæ­£å¸¸è¿ä½œã€‚
"""

_ORCHESTRATOR_SYSTEM_PROMPT_WITH_TOOLS = """\
ä½ æ˜¯ç¼ è®ºå½¢å¼åŒ–é¡¹ç›®çš„ç¼–æŽ’è€…ä»£ç†ï¼Œæ‹¥æœ‰ä»£ç åº“çš„è¯­ä¹‰çº§è®¿é—®èƒ½åŠ›ã€‚

ä½ å¯ä»¥ä½¿ç”¨å·¥å…·æ¥ç†è§£ä»£ç ç»“æž„å’Œå…³ç³»ï¼Œç„¶åŽåšå‡ºå†³ç­–ã€‚

## å››åˆ†æ³•ï¼ˆä½ çš„å†³ç­–æ¡†æž¶ï¼‰

- å®šç† / è¡ŒåŠ¨ â†’ ä¸åˆ°ä½ è¿™é‡Œï¼ˆClaude è‡ªè¡Œå¤„ç†ï¼‰
- **é€‰æ‹©**ï¼šå¤šç§åˆç†æ–¹æ¡ˆï¼Œéœ€ä»·å€¼åˆ¤æ–­ â†’ **ä½ æ¥å†³æ–­**
- **è¯­æ³•è®°å½•**ï¼šå·²åœ¨è¿ä½œä½†æœªæ˜¾å¼åŒ–çš„è§„åˆ™ â†’ **ä½ æ¥è¾¨è®¤**

## å†³ç­–åŽŸåˆ™

1. æ¦‚å¿µä¼˜å…ˆäºŽä»£ç 
2. ä¸ç»•è¿‡çŸ›ç›¾
3. å¯¹è±¡å¦å®šå¯¹è±¡ï¼ˆä¸å…è®¸è¶…æ—¶/é˜ˆå€¼å¦å®šï¼‰
4. çº§åˆ« = é€’å½’å±‚çº§
5. è°±ç³»ä¼˜å…ˆäºŽæ±‡æ€»
6. æº¯æºæ ‡ç­¾å¿…é¡»æ ‡æ³¨

## è¾“å‡ºè¦æ±‚

1. **å†³ç­–**ï¼šæ˜Žç¡®é€‰æ‹©
2. **æŽ¨ç†é“¾**ï¼šä¸ºä»€ä¹ˆé€‰è¿™ä¸ª
3. **è¾¹ç•Œæ¡ä»¶**ï¼šä½•æ—¶åº”æŽ¨ç¿»
4. **é£Žé™©**ï¼šå¯èƒ½çš„é—®é¢˜

å¼•ç”¨å…·ä½“ä»£ç ä½ç½®æ”¯æ’‘ä½ çš„åˆ¤æ–­ã€‚
"""

_DECIDE_TEMPLATE = """\
## å†³ç­–è¯·æ±‚

{subject}

## ä¸Šä¸‹æ–‡

{context}

## è¦æ±‚

ä½ æ˜¯ç¼–æŽ’è€…ä»£ç†ã€‚è¯·åšå‡ºæ˜Žç¡®å†³ç­–ã€‚

è¾“å‡ºæ ¼å¼ï¼š
- **å†³ç­–**ï¼š[ä½ çš„é€‰æ‹©]
- **æŽ¨ç†é“¾**ï¼š[ä¸ºä»€ä¹ˆ]
- **è¾¹ç•Œæ¡ä»¶**ï¼š[ä½•æ—¶åº”æŽ¨ç¿»æ­¤å†³ç­–]
- **é£Žé™©**ï¼š[å¯èƒ½çš„é—®é¢˜]
- **æº¯æº**ï¼š[æ—§ç¼ è®º] / [æ—§ç¼ è®º:éšå«] / [æ—§ç¼ è®º:é€‰æ‹©] / [æ–°ç¼ è®º]
"""

_DERIVE_SYSTEM_PROMPT = """\
You are a Formal Mathematical Proof Engine. Your task is to derive or prove \
the given statement strictly within the specified domain.

Capabilities:
- Universal Domain Support: Topology, Set Theory, Recursion Theory, \
Number Theory, Geometry, Formalized Chanlun System, and more.
- Strict Rigor: You do not guess. If a step is not justified by a definition \
or a previous lemma, the derivation fails.
- Axiomatic Isolation: Respect the boundaries of the specified domain. \
Do not mix axioms from different systems unless explicitly permitted.

Output Format (Strict):
### 1. Formal Restatement (å½¢å¼åŒ–é‡è¿°)
Translate into formal mathematical notation. Define all symbols.

### 2. Definitions & Axioms (å®šä¹‰ä¸Žå…¬ç†)
List specific definitions and axioms used as foundation.

### 3. Proof Chain (æŽ¨å¯¼é“¾)
Step-by-step logical deduction. Each step must reference a Definition, \
Axiom, or previous Step.
Format: Step N: [Assertion] (by [Justification])

### 4. Conclusion (ç»“è®º)
PROVEN (å¾—è¯), DISPROVEN (è¯ä¼ª), or UNDECIDABLE (ä¸å¯åˆ¤å®š).
End with Q.E.D. if proven.

Constraints:
- No ambiguity: if a term is ambiguous, declare UNDECIDABLE and request \
a definition.
- No time-based or subjective arguments. Use only structural properties.
- In Chanlun contexts, respect recursive nature of levels.
"""

_DERIVE_SYSTEM_PROMPT_WITH_TOOLS = """\
You are a Formal Mathematical Proof Engine with semantic code access. \
Your task is to derive or prove the given statement strictly within the \
specified domain.

You can use tools to inspect code definitions, type structures, and \
relationships. Use them to ground your proof in actual implementation.

Capabilities:
- Universal Domain Support: Topology, Set Theory, Recursion Theory, \
Number Theory, Geometry, Formalized Chanlun System, and more.
- Strict Rigor: You do not guess. If a step is not justified by a definition \
or a previous lemma, the derivation fails.
- Axiomatic Isolation: Respect the boundaries of the specified domain. \
Do not mix axioms from different systems unless explicitly permitted.
- Code Grounding: Reference concrete code symbols and file paths.

Output Format (Strict):
### 1. Formal Restatement (å½¢å¼åŒ–é‡è¿°)
Translate into formal mathematical notation. Define all symbols.

### 2. Definitions & Axioms (å®šä¹‰ä¸Žå…¬ç†)
List specific definitions and axioms used as foundation.

### 3. Proof Chain (æŽ¨å¯¼é“¾)
Step-by-step logical deduction. Each step must reference a Definition, \
Axiom, or previous Step.
Format: Step N: [Assertion] (by [Justification])

### 4. Conclusion (ç»“è®º)
PROVEN (å¾—è¯), DISPROVEN (è¯ä¼ª), or UNDECIDABLE (ä¸å¯åˆ¤å®š).
End with Q.E.D. if proven.

Constraints:
- No ambiguity: if a term is ambiguous, declare UNDECIDABLE and request \
a definition.
- No time-based or subjective arguments. Use only structural properties.
- In Chanlun contexts, respect recursive nature of levels.
- Reference concrete code locations to support your reasoning.
"""

_DERIVE_TEMPLATE = """\
**Domain**: {domain}
**Statement**: {subject}
**Axiomatic Context**: {context}
"""


@dataclass(frozen=True, slots=True)
class ChallengeResult:
    """è´¨è¯¢ç»“æžœã€‚"""

    mode: Literal["challenge", "verify", "decide", "derive"]
    subject: str
    response: str
    model: str
    tool_calls: tuple[str, ...] = ()  # MCP å·¥å…·è°ƒç”¨åŽ†å²æ‘˜è¦
    reasoning_chain: tuple[dict, ...] = ()  # å®Œæ•´æŽ¨ç†é“¾ï¼ˆthought/tool_call/tool_resultï¼‰


class GeminiChallenger:
    """Gemini è´¨è¯¢å·¥ä½çš„æ ¸å¿ƒç±»ã€‚

    Parameters
    ----------
    api_key : str | None
        Google API Keyã€‚None æ—¶ä»Ž GOOGLE_API_KEY çŽ¯å¢ƒå˜é‡è¯»å–ã€‚
    model : str
        æ¨¡åž‹åç§°ï¼Œé»˜è®¤ gemini-3-pro-previewã€‚
    """

    def __init__(
        self,
        api_key: str | None = None,
        model: str = _MODEL,
    ) -> None:
        key = api_key or os.environ.get("GOOGLE_API_KEY", "")
        if not key:
            raise ValueError(
                "GOOGLE_API_KEY æœªè®¾ç½®ã€‚"
                "è¯·åœ¨ .env ä¸­è®¾ç½®æˆ–ä¼ å…¥ api_key å‚æ•°ã€‚"
            )
        self._client = genai.Client(api_key=key)
        self._model = model

    def _call_with_fallback(
        self,
        prompt: str,
        temperature: float,
        system_prompt: str = _SYSTEM_PROMPT,
    ) -> tuple[str, str]:
        """è°ƒç”¨ Gemini APIï¼Œä¸»æ¨¡åž‹ 503 æ—¶è‡ªåŠ¨é™çº§åˆ° fallbackã€‚

        Returns (response_text, actual_model_used)ã€‚
        """
        for model in (self._model, _FALLBACK_MODEL):
            try:
                response = self._client.models.generate_content(
                    model=model,
                    contents=prompt,
                    config=genai.types.GenerateContentConfig(
                        system_instruction=system_prompt,
                        temperature=temperature,
                    ),
                )
                return response.text or "", model
            except (genai_errors.ServerError, genai_errors.ClientError):
                if model == self._model and model != _FALLBACK_MODEL:
                    logger.warning(
                        "%s ä¸å¯ç”¨ï¼Œé™çº§åˆ° %s",
                        model,
                        _FALLBACK_MODEL,
                    )
                    continue
                raise
        # unreachable, but satisfies type checker
        raise RuntimeError("æ‰€æœ‰æ¨¡åž‹å‡ä¸å¯ç”¨")  # pragma: no cover

    def challenge(self, subject: str, context: str = "") -> ChallengeResult:
        """å¯¹ç»™å®šä¸»é¢˜å‘èµ·è´¨è¯¢ã€‚

        Parameters
        ----------
        subject : str
            è´¨è¯¢ç›®æ ‡ï¼ˆå®šä¹‰ã€ä»£ç ã€æŽ¨ç†é“¾ç­‰ï¼‰ã€‚
        context : str
            ç›¸å…³ä¸Šä¸‹æ–‡ä¿¡æ¯ã€‚

        Returns
        -------
        ChallengeResult
        """
        prompt = _CHALLENGE_TEMPLATE.format(subject=subject, context=context)
        text, model_used = self._call_with_fallback(prompt, temperature=0.3)
        return ChallengeResult(
            mode="challenge",
            subject=subject,
            response=text,
            model=model_used,
        )

    def verify(self, subject: str, context: str = "") -> ChallengeResult:
        """éªŒè¯ç»™å®šæ–­è¨€æ˜¯å¦æˆç«‹ã€‚

        Parameters
        ----------
        subject : str
            éªŒè¯ç›®æ ‡ã€‚
        context : str
            ç›¸å…³ä¸Šä¸‹æ–‡ä¿¡æ¯ã€‚

        Returns
        -------
        ChallengeResult
        """
        prompt = _VERIFY_TEMPLATE.format(subject=subject, context=context)
        text, model_used = self._call_with_fallback(prompt, temperature=0.1)
        return ChallengeResult(
            mode="verify",
            subject=subject,
            response=text,
            model=model_used,
        )

    def decide(self, subject: str, context: str = "") -> ChallengeResult:
        """ç¼–æŽ’è€…ä»£ç†å†³ç­–ï¼ˆçº¯æ–‡æœ¬æ¨¡å¼ï¼‰ã€‚

        Parameters
        ----------
        subject : str
            å†³ç­–è¯·æ±‚ï¼ˆé€‰æ‹©ç±»æˆ–è¯­æ³•è®°å½•ç±»ï¼‰ã€‚
        context : str
            ç›¸å…³ä¸Šä¸‹æ–‡ä¿¡æ¯ã€‚

        Returns
        -------
        ChallengeResult
        """
        prompt = _DECIDE_TEMPLATE.format(subject=subject, context=context)
        text, model_used = self._call_with_fallback(
            prompt, temperature=0.2, system_prompt=_ORCHESTRATOR_SYSTEM_PROMPT,
        )
        return ChallengeResult(
            mode="decide",
            subject=subject,
            response=text,
            model=model_used,
        )

    def derive(
        self, subject: str, context: str = "", domain: str = "General Mathematics",
    ) -> ChallengeResult:
        """å½¢å¼æŽ¨å¯¼ï¼ˆçº¯æ–‡æœ¬æ¨¡å¼ï¼‰ã€‚

        Parameters
        ----------
        subject : str
            å¾…æŽ¨å¯¼/è¯æ˜Žçš„å‘½é¢˜ã€‚
        context : str
            å…¬ç†ä¸Šä¸‹æ–‡ï¼ˆç¼ è®ºå®šä¹‰ã€æ•°å­¦å…¬ç†ç­‰ï¼‰ã€‚
        domain : str
            æŽ¨å¯¼æ‰€åœ¨çš„å…¬ç†åŸŸï¼ˆé»˜è®¤ General Mathematicsï¼‰ã€‚

        Returns
        -------
        ChallengeResult
        """
        prompt = _DERIVE_TEMPLATE.format(
            domain=domain, subject=subject, context=context,
        )
        text, model_used = self._call_with_fallback(
            prompt, temperature=0.1, system_prompt=_DERIVE_SYSTEM_PROMPT,
        )
        return ChallengeResult(
            mode="derive",
            subject=subject,
            response=text,
            model=model_used,
        )

    # â”€â”€ MCP å·¥å…·æ¨¡å¼ï¼ˆasyncï¼‰ â”€â”€

    async def _call_with_tools_and_fallback(
        self,
        prompt: str,
        temperature: float,
        session: object,  # mcp.client.session.ClientSession
        max_tool_calls: int = 20,
        system_prompt: str = _SYSTEM_PROMPT_WITH_TOOLS,
    ) -> tuple[str, str, tuple[str, ...], tuple[dict, ...]]:
        """Gemini + MCP è‡ªåŠ¨ function calling å¾ªçŽ¯ã€‚

        google-genai SDK åŽŸç”Ÿæ”¯æŒ MCP ClientSession ä½œä¸º toolã€‚
        SDK è‡ªåŠ¨å¤„ç†ï¼šåˆ—å‡ºå·¥å…· â†’ Gemini å‘ function call â†’
        SDK æ‰§è¡Œ â†’ ç»“æžœå›žä¼  â†’ é‡å¤ã€‚

        Returns (response_text, actual_model, tool_call_summaries, reasoning_chain)ã€‚
        """
        for model in (self._model, _FALLBACK_MODEL):
            try:
                response = await self._client.aio.models.generate_content(
                    model=model,
                    contents=prompt,
                    config=genai_types.GenerateContentConfig(
                        system_instruction=system_prompt,
                        temperature=temperature,
                        tools=[session],
                        automatic_function_calling=genai_types.AutomaticFunctionCallingConfig(
                            maximum_remote_calls=max_tool_calls,
                        ),
                    ),
                )
                # æå–å·¥å…·è°ƒç”¨åŽ†å² + å®Œæ•´æŽ¨ç†é“¾
                tool_calls: list[str] = []
                chain: list[dict] = []
                history = getattr(
                    response, "automatic_function_calling_history", None,
                )
                if history:
                    for entry in history:
                        for part in getattr(entry, "parts", []):
                            # Gemini çš„æ–‡æœ¬æŽ¨ç†
                            text = getattr(part, "text", None)
                            if text and text.strip():
                                chain.append({
                                    "type": "thought",
                                    "content": text.strip(),
                                })
                            # å·¥å…·è°ƒç”¨è¯·æ±‚
                            fc = getattr(part, "function_call", None)
                            if fc:
                                args = dict(fc.args or {})
                                summary = f"{fc.name}({', '.join(f'{k}={v!r}' for k, v in args.items())})"
                                tool_calls.append(summary)
                                chain.append({
                                    "type": "tool_call",
                                    "name": fc.name,
                                    "args": args,
                                })
                            # å·¥å…·è¿”å›žç»“æžœ
                            fr = getattr(part, "function_response", None)
                            if fr:
                                content = str(getattr(fr, "response", ""))
                                chain.append({
                                    "type": "tool_result",
                                    "name": getattr(fr, "name", ""),
                                    "content": content[:500] if len(content) > 500 else content,
                                })
                return (
                    response.text or "",
                    model,
                    tuple(tool_calls),
                    tuple(chain),
                )
            except (genai_errors.ServerError, genai_errors.ClientError):
                if model == self._model and model != _FALLBACK_MODEL:
                    logger.warning(
                        "%s ä¸å¯ç”¨ï¼Œé™çº§åˆ° %s",
                        model,
                        _FALLBACK_MODEL,
                    )
                    continue
                raise
        raise RuntimeError("æ‰€æœ‰æ¨¡åž‹å‡ä¸å¯ç”¨")  # pragma: no cover

    async def challenge_with_tools(
        self,
        subject: str,
        context: str = "",
        *,
        session: object | None = None,
        max_tool_calls: int = 20,
    ) -> ChallengeResult:
        """MCP å·¥å…·å¢žå¼ºè´¨è¯¢ã€‚Gemini å¯è‡ªä¸»å¯¼èˆªä»£ç åº“ã€‚

        Parameters
        ----------
        subject : str
            è´¨è¯¢ç›®æ ‡ã€‚
        context : str
            é¢å¤–ä¸Šä¸‹æ–‡ã€‚
        session : mcp ClientSession | None
            MCP ä¼šè¯ã€‚None æ—¶è‡ªåŠ¨è¿žæŽ¥ Serenaã€‚
        max_tool_calls : int
            æœ€å¤§å·¥å…·è°ƒç”¨æ¬¡æ•°ã€‚
        """
        prompt = _CHALLENGE_TEMPLATE.format(subject=subject, context=context)
        if session is not None:
            text, model_used, calls, chain = await self._call_with_tools_and_fallback(
                prompt, 0.3, session, max_tool_calls,
            )
            return ChallengeResult(
                mode="challenge",
                subject=subject,
                response=text,
                model=model_used,
                tool_calls=calls,
                reasoning_chain=chain,
            )
        # è‡ªåŠ¨è¿žæŽ¥ Serena
        from newchan.mcp_bridge import SerenaConfig, mcp_session

        async with mcp_session(SerenaConfig()) as sess:
            text, model_used, calls, chain = await self._call_with_tools_and_fallback(
                prompt, 0.3, sess, max_tool_calls,
            )
        return ChallengeResult(
            mode="challenge",
            subject=subject,
            response=text,
            model=model_used,
            tool_calls=calls,
            reasoning_chain=chain,
        )

    async def verify_with_tools(
        self,
        subject: str,
        context: str = "",
        *,
        session: object | None = None,
        max_tool_calls: int = 20,
    ) -> ChallengeResult:
        """MCP å·¥å…·å¢žå¼ºéªŒè¯ã€‚Gemini å¯è‡ªä¸»å¯¼èˆªä»£ç åº“ã€‚

        Parameters
        ----------
        subject : str
            éªŒè¯ç›®æ ‡ã€‚
        context : str
            é¢å¤–ä¸Šä¸‹æ–‡ã€‚
        session : mcp ClientSession | None
            MCP ä¼šè¯ã€‚None æ—¶è‡ªåŠ¨è¿žæŽ¥ Serenaã€‚
        max_tool_calls : int
            æœ€å¤§å·¥å…·è°ƒç”¨æ¬¡æ•°ã€‚
        """
        prompt = _VERIFY_TEMPLATE.format(subject=subject, context=context)
        if session is not None:
            text, model_used, calls, chain = await self._call_with_tools_and_fallback(
                prompt, 0.1, session, max_tool_calls,
            )
            return ChallengeResult(
                mode="verify",
                subject=subject,
                response=text,
                model=model_used,
                tool_calls=calls,
                reasoning_chain=chain,
            )
        from newchan.mcp_bridge import SerenaConfig, mcp_session

        async with mcp_session(SerenaConfig()) as sess:
            text, model_used, calls, chain = await self._call_with_tools_and_fallback(
                prompt, 0.1, sess, max_tool_calls,
            )
        return ChallengeResult(
            mode="verify",
            subject=subject,
            response=text,
            model=model_used,
            tool_calls=calls,
            reasoning_chain=chain,
        )

    async def decide_with_tools(
        self,
        subject: str,
        context: str = "",
        *,
        session: object | None = None,
        max_tool_calls: int = 20,
    ) -> ChallengeResult:
        """MCP å·¥å…·å¢žå¼ºç¼–æŽ’è€…å†³ç­–ã€‚Gemini å¯è‡ªä¸»å¯¼èˆªä»£ç åº“ã€‚

        Parameters
        ----------
        subject : str
            å†³ç­–è¯·æ±‚ã€‚
        context : str
            é¢å¤–ä¸Šä¸‹æ–‡ã€‚
        session : mcp ClientSession | None
            MCP ä¼šè¯ã€‚None æ—¶è‡ªåŠ¨è¿žæŽ¥ Serenaã€‚
        max_tool_calls : int
            æœ€å¤§å·¥å…·è°ƒç”¨æ¬¡æ•°ã€‚
        """
        prompt = _DECIDE_TEMPLATE.format(subject=subject, context=context)
        if session is not None:
            text, model_used, calls, chain = await self._call_with_tools_and_fallback(
                prompt, 0.2, session, max_tool_calls,
                system_prompt=_ORCHESTRATOR_SYSTEM_PROMPT_WITH_TOOLS,
            )
            return ChallengeResult(
                mode="decide",
                subject=subject,
                response=text,
                model=model_used,
                tool_calls=calls,
                reasoning_chain=chain,
            )
        from newchan.mcp_bridge import SerenaConfig, mcp_session

        async with mcp_session(SerenaConfig()) as sess:
            text, model_used, calls, chain = await self._call_with_tools_and_fallback(
                prompt, 0.2, sess, max_tool_calls,
                system_prompt=_ORCHESTRATOR_SYSTEM_PROMPT_WITH_TOOLS,
            )
        return ChallengeResult(
            mode="decide",
            subject=subject,
            response=text,
            model=model_used,
            tool_calls=calls,
            reasoning_chain=chain,
        )

    async def derive_with_tools(
        self,
        subject: str,
        context: str = "",
        domain: str = "General Mathematics",
        *,
        session: object | None = None,
        max_tool_calls: int = 20,
    ) -> ChallengeResult:
        """MCP å·¥å…·å¢žå¼ºå½¢å¼æŽ¨å¯¼ã€‚Gemini å¯è‡ªä¸»å¯¼èˆªä»£ç åº“ã€‚

        Parameters
        ----------
        subject : str
            å¾…æŽ¨å¯¼/è¯æ˜Žçš„å‘½é¢˜ã€‚
        context : str
            å…¬ç†ä¸Šä¸‹æ–‡ã€‚
        domain : str
            æŽ¨å¯¼æ‰€åœ¨çš„å…¬ç†åŸŸã€‚
        session : mcp ClientSession | None
            MCP ä¼šè¯ã€‚None æ—¶è‡ªåŠ¨è¿žæŽ¥ Serenaã€‚
        max_tool_calls : int
            æœ€å¤§å·¥å…·è°ƒç”¨æ¬¡æ•°ã€‚
        """
        prompt = _DERIVE_TEMPLATE.format(
            domain=domain, subject=subject, context=context,
        )
        if session is not None:
            text, model_used, calls, chain = await self._call_with_tools_and_fallback(
                prompt, 0.1, session, max_tool_calls,
                system_prompt=_DERIVE_SYSTEM_PROMPT_WITH_TOOLS,
            )
            return ChallengeResult(
                mode="derive",
                subject=subject,
                response=text,
                model=model_used,
                tool_calls=calls,
                reasoning_chain=chain,
            )
        from newchan.mcp_bridge import SerenaConfig, mcp_session

        async with mcp_session(SerenaConfig()) as sess:
            text, model_used, calls, chain = await self._call_with_tools_and_fallback(
                prompt, 0.1, sess, max_tool_calls,
                system_prompt=_DERIVE_SYSTEM_PROMPT_WITH_TOOLS,
            )
        return ChallengeResult(
            mode="derive",
            subject=subject,
            response=text,
            model=model_used,
            tool_calls=calls,
            reasoning_chain=chain,
        )


# â”€â”€ æ¨¡å—çº§ä¾¿æ·å‡½æ•° â”€â”€

_default_challenger: GeminiChallenger | None = None


def _get_challenger() -> GeminiChallenger:
    global _default_challenger
    if _default_challenger is None:
        _default_challenger = GeminiChallenger()
    return _default_challenger


def challenge(subject: str, context: str = "") -> ChallengeResult:
    """æ¨¡å—çº§è´¨è¯¢ï¼ˆçº¯æ–‡æœ¬æ¨¡å¼ï¼‰ã€‚"""
    return _get_challenger().challenge(subject, context)


def verify(subject: str, context: str = "") -> ChallengeResult:
    """æ¨¡å—çº§éªŒè¯ï¼ˆçº¯æ–‡æœ¬æ¨¡å¼ï¼‰ã€‚"""
    return _get_challenger().verify(subject, context)


async def achallenge(
    subject: str,
    context: str = "",
    *,
    max_tool_calls: int = 20,
) -> ChallengeResult:
    """æ¨¡å—çº§ MCP å·¥å…·å¢žå¼ºè´¨è¯¢ï¼ˆasyncï¼Œè‡ªåŠ¨è¿žæŽ¥ Serenaï¼‰ã€‚"""
    return await _get_challenger().challenge_with_tools(
        subject, context, max_tool_calls=max_tool_calls,
    )


async def averify(
    subject: str,
    context: str = "",
    *,
    max_tool_calls: int = 20,
) -> ChallengeResult:
    """æ¨¡å—çº§ MCP å·¥å…·å¢žå¼ºéªŒè¯ï¼ˆasyncï¼Œè‡ªåŠ¨è¿žæŽ¥ Serenaï¼‰ã€‚"""
    return await _get_challenger().verify_with_tools(
        subject, context, max_tool_calls=max_tool_calls,
    )


def decide(subject: str, context: str = "") -> ChallengeResult:
    """æ¨¡å—çº§ç¼–æŽ’è€…ä»£ç†å†³ç­–ï¼ˆçº¯æ–‡æœ¬æ¨¡å¼ï¼‰ã€‚"""
    return _get_challenger().decide(subject, context)


async def adecide(
    subject: str,
    context: str = "",
    *,
    max_tool_calls: int = 20,
) -> ChallengeResult:
    """æ¨¡å—çº§ MCP å·¥å…·å¢žå¼ºå†³ç­–ï¼ˆasyncï¼Œè‡ªåŠ¨è¿žæŽ¥ Serenaï¼‰ã€‚"""
    return await _get_challenger().decide_with_tools(
        subject, context, max_tool_calls=max_tool_calls,
    )


def derive(
    subject: str, context: str = "", domain: str = "General Mathematics",
) -> ChallengeResult:
    """æ¨¡å—çº§å½¢å¼æŽ¨å¯¼ï¼ˆçº¯æ–‡æœ¬æ¨¡å¼ï¼‰ã€‚"""
    return _get_challenger().derive(subject, context, domain)


async def aderive(
    subject: str,
    context: str = "",
    domain: str = "General Mathematics",
    *,
    max_tool_calls: int = 20,
) -> ChallengeResult:
    """æ¨¡å—çº§ MCP å·¥å…·å¢žå¼ºå½¢å¼æŽ¨å¯¼ï¼ˆasyncï¼Œè‡ªåŠ¨è¿žæŽ¥ Serenaï¼‰ã€‚"""
    return await _get_challenger().derive_with_tools(
        subject, context, domain, max_tool_calls=max_tool_calls,
    )


# â”€â”€ CLI å…¥å£ â”€â”€

if __name__ == "__main__":
    import argparse
    import sys

    from dotenv import load_dotenv

    load_dotenv()

    parser = argparse.ArgumentParser(description="Gemini è´¨è¯¢å·¥ä½ CLI")
    parser.add_argument(
        "mode",
        choices=["challenge", "verify", "decide", "derive"],
        help="è´¨è¯¢æ¨¡å¼",
    )
    parser.add_argument(
        "subject",
        help="è´¨è¯¢/éªŒè¯ç›®æ ‡",
    )
    parser.add_argument(
        "--context",
        default="",
        help="ä¸Šä¸‹æ–‡ä¿¡æ¯",
    )
    parser.add_argument(
        "--context-file",
        default=None,
        help="ä»Žæ–‡ä»¶è¯»å–ä¸Šä¸‹æ–‡",
    )
    parser.add_argument(
        "--domain",
        default="General Mathematics",
        help="æŽ¨å¯¼æ‰€åœ¨çš„å…¬ç†åŸŸï¼ˆä»… derive æ¨¡å¼ï¼Œé»˜è®¤ General Mathematicsï¼‰",
    )
    parser.add_argument(
        "--tools",
        action="store_true",
        help="å¯ç”¨ MCP å·¥å…·æ¨¡å¼ï¼ˆGemini å¯è®¿é—® Serena è¯­ä¹‰å·¥å…·ï¼‰",
    )
    parser.add_argument(
        "--max-tool-calls",
        type=int,
        default=20,
        help="MCP æ¨¡å¼ä¸‹æœ€å¤§å·¥å…·è°ƒç”¨æ¬¡æ•°ï¼ˆé»˜è®¤ 20ï¼‰",
    )
    parser.add_argument(
        "--verbose",
        action="store_true",
        help="è¾“å‡ºå®Œæ•´æŽ¨ç†é“¾ï¼ˆGemini çš„æ¯æ­¥æ€è€ƒ + å·¥å…·è°ƒç”¨ + å·¥å…·è¿”å›žï¼‰",
    )
    args = parser.parse_args()

    ctx = args.context
    if args.context_file:
        with open(args.context_file, encoding="utf-8") as f:
            ctx = f.read()

    try:
        challenger = GeminiChallenger()
    except ValueError as e:
        print(f"Error: {e}", file=sys.stderr)
        sys.exit(1)

    if args.tools:
        # MCP å·¥å…·æ¨¡å¼ï¼ˆasyncï¼‰
        async def _run() -> ChallengeResult:
            if args.mode == "challenge":
                return await challenger.challenge_with_tools(
                    args.subject, ctx, max_tool_calls=args.max_tool_calls,
                )
            if args.mode == "decide":
                return await challenger.decide_with_tools(
                    args.subject, ctx, max_tool_calls=args.max_tool_calls,
                )
            if args.mode == "derive":
                return await challenger.derive_with_tools(
                    args.subject, ctx, args.domain,
                    max_tool_calls=args.max_tool_calls,
                )
            return await challenger.verify_with_tools(
                args.subject, ctx, max_tool_calls=args.max_tool_calls,
            )

        result = asyncio.run(_run())
    else:
        # çº¯æ–‡æœ¬æ¨¡å¼ï¼ˆsyncï¼‰
        if args.mode == "challenge":
            result = challenger.challenge(args.subject, ctx)
        elif args.mode == "decide":
            result = challenger.decide(args.subject, ctx)
        elif args.mode == "derive":
            result = challenger.derive(args.subject, ctx, args.domain)
        else:
            result = challenger.verify(args.subject, ctx)

    print(f"[{result.mode}] model={result.model}")
    if result.tool_calls:
        print(f"tool_calls ({len(result.tool_calls)}):")
        for tc in result.tool_calls:
            print(f"  â†’ {tc}")
    if args.verbose and result.reasoning_chain:
        print()
        print("=== Gemini æŽ¨ç†é“¾ ===")
        for i, step in enumerate(result.reasoning_chain, 1):
            stype = step["type"]
            if stype == "thought":
                print(f"[{i}] ðŸ’­ {step['content']}")
            elif stype == "tool_call":
                args_str = ", ".join(
                    f"{k}={v!r}" for k, v in step.get("args", {}).items()
                )
                print(f"[{i}] ðŸ” {step['name']}({args_str})")
            elif stype == "tool_result":
                content = step.get("content", "")
                preview = content[:200] + "..." if len(content) > 200 else content
                print(f"    â†’ {step.get('name', '')}: {preview}")
        print()
    print("=" * 60)
    print(result.response)
